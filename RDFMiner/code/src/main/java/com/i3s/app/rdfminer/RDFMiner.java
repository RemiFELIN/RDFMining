/**
 * 
 */
package com.i3s.app.rdfminer;

import com.i3s.app.rdfminer.grammar.evolutionary.CostGP;
import com.i3s.app.rdfminer.launcher.GrammaticalEvolution;
import com.i3s.app.rdfminer.launcher.Evaluator;
import com.i3s.app.rdfminer.output.Results;
import com.i3s.app.rdfminer.output.axiom.AxiomsResultsJSON;
import com.i3s.app.rdfminer.output.axiom.StatJSON;
import com.i3s.app.rdfminer.parameters.CmdLineParameters;
import org.apache.log4j.Logger;
import org.apache.log4j.PropertyConfigurator;
import org.json.JSONArray;
import org.json.JSONObject;
import org.kohsuke.args4j.CmdLineException;
import org.kohsuke.args4j.CmdLineParser;

import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.net.MalformedURLException;
import java.net.URISyntaxException;
import java.net.URL;
import java.nio.file.Files;
import java.nio.file.Path;
import java.util.List;
import java.util.concurrent.ExecutionException;

/**
 * The main class of the RDFMiner experimental tool.
 * <p>
 * More information about OWL 2 may be found in the
 * <a href="http://www.w3.org/TR/2012/REC-owl2-quick-reference-20121211/">OWL2
 * Quick Reference, 2nd Edition</a>.
 * </p>
 * 
 * @author Andrea G. B. Tettamanzi & RÃ©mi FELIN
 *
 */
public class RDFMiner {

	private static final Logger logger = Logger.getLogger(RDFMiner.class.getName());

	public static CmdLineParameters parameters = new CmdLineParameters();

	/**
	 * The output file in json
	 */
	public static FileWriter output;
	public static String outputFolder;
	
	// v1.0 evaluate data
	public static JSONArray axiomsList;
	// v1.2 miner data
	public static Results results;
	public static StatJSON stats;
	public static List<JSONObject> content;
	public static int type;

	/**
	 * A table of predicates, used in {@link CostGP}
	 */
	public static String[][] predicateTable;

	/**
	 * The entry point of the RDF Miner application.
	 */
	public static void main(String[] args) throws InterruptedException, ExecutionException, URISyntaxException, IOException {

		// Print the banner of RDF Miner
		System.out.println(Global.BANNER);
		
		// Configure the log4j loggers:
		PropertyConfigurator.configure(Global.LOG4J_PROPERTIES);
		
		// Parse the command-line parameters and options:
		CmdLineParser parser = new CmdLineParser(parameters);

		// if you have a wider console, you could increase the value;
		// here 80 is also the default
		parser.getProperties().withUsageWidth(80);

		try {
			// parse the arguments.
			parser.parseArgument(args);
		} catch (CmdLineException e) {
			// if there's a problem in the command line, you'll get this
			// exception. this will report an error message.
			System.err.println(e.getMessage());
			// print the list of available options
			System.err.println();
			parser.printUsage(System.out);
			System.err.println();
			return;
		}

		if (parameters.help) {
			// print the list of available options
			System.out.println();
			parser.printUsage(System.out);
			System.out.println();
			return;
		}
		
		logger.info("Number of processors avalaibles: " + Global.NB_THREADS);
		
		if(parameters.timeOut != 0)
			logger.info("Time cap initialized at " + parameters.timeOut + " seconde(s)");
		
		// Load librdfminer_entity_Entity.so generated by ./compile_c_code.sh (see /scripts folder)
		System.loadLibrary("rdfminer_entity_Entity");

		// Create cache folder if it not already exists
		if(!(new File(Global.CACHE_PATH)).exists()) {
			boolean created = (new File(Global.CACHE_PATH)).mkdir();
			if(created)
				logger.info("Cache folder successfully created");
		}
		
		if(parameters.singleAxiom == null) {
			logger.info("Output folder: " + Global.OUTPUT_PATH + parameters.resultFolder);
			if(!(new File(Global.OUTPUT_PATH + parameters.resultFolder)).exists()) {
				boolean created = (new File(Global.OUTPUT_PATH + parameters.resultFolder)).mkdirs();
				if(created)
					logger.info("Successfully created !");
			}
			RDFMiner.outputFolder = Global.OUTPUT_PATH + parameters.resultFolder;
		}

		// get the mode used ( SHACL Shapes ; OWL 2 Axioms )
//		if(parameters.useShaclMode) {
//			mode = new Mode(TypeMode.SHACL_SHAPE);
////			results = new ShapesResultsJSON();
//		} else {
//			mode = new Mode(TypeMode.AXIOMS);
//		results = new AxiomsResultsJSON();
//		}
		stats = new StatJSON();

		// define a SPARQL Endpoint to use if provided
		if(parameters.targetSparqlEndpoint != null) {
			logger.info("(--target-endpoint) a target SPARQL Endpoint is specified !");
			try {
				// Test if the given url is a valid URL or not
				new URL(parameters.targetSparqlEndpoint);
			} catch (MalformedURLException e) {
				logger.error("The given SPARQL Endpoint is not a valid URL ...");
				System.exit(1);
			}
			Global.TARGET_SPARQL_ENDPOINT = parameters.targetSparqlEndpoint;
			logger.info("RDFMiner will query the following link in SERVICE clause: " + Global.TARGET_SPARQL_ENDPOINT);
		} else {
			Global.TARGET_SPARQL_ENDPOINT = Global.VIRTUOSO_DBPEDIA_2015_04_SPARQL_ENDPOINT;
			logger.warn("No target database specified !");
			logger.warn("RDFMiner will query the following link in SERVICE clause: " + Global.TARGET_SPARQL_ENDPOINT);
			logger.warn("This database contains a dump of DBPedia 2015-04 ...");
		}
		// define a training dataset if it's provided
		if(parameters.trainSparqlEndpoint != null) {
			logger.info("(--train-endpoint) a training SPARQL Endpoint is specified !");
			try {
				// Test if the given url is a valid URL or not
				new URL(parameters.trainSparqlEndpoint);
			} catch (MalformedURLException e) {
				logger.error("The given SPARQL Endpoint is not a valid URL ...");
				System.exit(1);
			}
			Global.TRAINING_SPARQL_ENDPOINT = parameters.trainSparqlEndpoint;
			logger.info("RDFMiner will query the following link in SERVICE clause: " + Global.TRAINING_SPARQL_ENDPOINT);
		} else if(parameters.grammaticalEvolution) {
			logger.warn("Grammatical evolution activated without training dataset specified !");
			logger.warn("RDFMiner will query the following link in SERVICE clause: " + Global.TRAINING_SPARQL_ENDPOINT);
			logger.warn("This database contains a subset (1%) of a dump of DBPedia 2015-04 ...");
		}

		// define a set of prefixes provided by user (with -prefix option), else use the default prefixes
		if(parameters.prefixesFile != null) {
			File prefixesFile = new File(parameters.prefixesFile);
			if(prefixesFile.exists()) {
				logger.info("(--prefixes) RDFMiner will use the following prefixes file");
				logger.info(prefixesFile.getAbsolutePath());
				try {
					Global.PREFIXES = Files.readString(Path.of(prefixesFile.getAbsolutePath()));
				} catch (IOException e) {
					logger.error("Error when reading the prefix file ...");
					logger.error(e.getMessage());
					System.exit(1);
				}
			} else {
				logger.error("The given prefixes file does not exists ...");
				logger.warn("RDFMiner will use the default prefixes to perform SPARQL queries ...");
			}
		} else {
			logger.info("RDFMiner will use the default prefixes to perform SPARQL queries ...");
		}

		// If parameters.grammaticalEvolution is used, we launch an instance of
		// Grammar-based genetic programming
		if(parameters.grammaticalEvolution) {
			try {
				GrammaticalEvolution.run(parameters);
			} catch (Exception e) {
				e.printStackTrace();
				System.exit(0);
			}
		} else {
			// launch evaluator !
			new Evaluator();
		}
	}

}
